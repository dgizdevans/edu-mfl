{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08bf3ac1",
   "metadata": {},
   "source": [
    "# Prediction of the Output Power of a Combined Cycle Power Plant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0917fa7",
   "metadata": {},
   "source": [
    "*Machine Learning Foundations for Product Managers by Duke University and Coursera* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b80657",
   "metadata": {},
   "source": [
    "Course project by Dmitrijs Giždevans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415f236",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc999f47",
   "metadata": {},
   "source": [
    "## Project topic:\n",
    "\n",
    "In this project we will build a model to predict the electrical energy output of a Combined Cycle Power Plant, which uses a combination of gas turbines, steam turbines, and heat recovery steam generators to generate power.  We have a set of 9568 hourly average ambient environmental readings from sensors at the power plant which we will use in our model.\n",
    "\n",
    "The columns in the data consist of hourly average ambient variables:\n",
    "- Temperature (T) in the range 1.81°C to 37.11°C,\n",
    "- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n",
    "- Relative Humidity (RH) in the range 25.56% to 100.16%\n",
    "- Exhaust Vacuum (V) in the range 25.36-81.56 cm Hg\n",
    "- Net hourly electrical energy output (PE) 420.26-495.76 MW (Target we are trying to predict)\n",
    "\n",
    "The dataset may be downloaded as a csv file.  Note that Safari users may have to navigate to File -> Save As and select the option \"Save as source\" to download the file.  Once you have downloaded the data, please review the Project Modeling Options reading and select a method of working with the data to build your model: 1) using Excel, 2) **using Python**, or 3) using Google AutoML.\n",
    "\n",
    "*Data source:*\n",
    "\n",
    "Pınar Tüfekci, Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods, International Journal of Electrical Power & Energy Systems, Volume 60, September 2014, Pages 126-140, ISSN 0142-0615.\n",
    "\n",
    "Heysem Kaya, Pınar Tüfekci , Sadık Fikret Gürgen: Local and Global Learning Methods for Predicting Power of a Combined Gas & Steam Turbine, Proceedings of the International Conference on Emerging Trends in Computer and Electronics Engineering ICETCEE 2012, pp. 13-18 (Mar. 2012, Dubai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886390bd",
   "metadata": {},
   "source": [
    "## Project agenda\n",
    "\n",
    "1. Preparing data for analysis.\n",
    "2. Data analysis and approach of modeling. \n",
    "3. Model building and calc of metrics for evaluation.\n",
    "4. Model evaluation and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259298e",
   "metadata": {},
   "source": [
    "## 1. Preparing data for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d81cf0",
   "metadata": {},
   "source": [
    "In the beginning, we simply prepare the data by downloading it to the local environment and saving it in a Dataframe that is convenient for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d46607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Assign dataset location url of file: url\n",
    "url = 'https://storage.googleapis.com/aipi_datasets/CCPP_data.csv'\n",
    "\n",
    "# Save dataset file locally\n",
    "urlretrieve(url,'CCPP_data.csv')\n",
    "\n",
    "# Load dataset to dataframe:\n",
    "df = pd.read_csv('CCPP_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5f07b",
   "metadata": {},
   "source": [
    "Next, we check how good the data is and how homogeneous it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ae58e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AT      V       AP     RH      PE\n",
      "0     14.96  41.76  1024.07  73.17  463.26\n",
      "1     25.18  62.96  1020.04  59.08  444.37\n",
      "2      5.11  39.40  1012.16  92.14  488.56\n",
      "3     20.86  57.32  1010.24  76.64  446.48\n",
      "4     10.82  37.50  1009.23  96.62  473.90\n",
      "...     ...    ...      ...    ...     ...\n",
      "9562  14.02  40.10  1015.56  82.44  467.32\n",
      "9563  16.65  49.69  1014.01  91.00  460.03\n",
      "9564  13.19  39.18  1023.67  66.78  469.62\n",
      "9565  31.32  74.33  1012.92  36.48  429.57\n",
      "9566  24.48  69.45  1013.86  62.39  435.74\n",
      "\n",
      "[9567 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking overall data integrity\n",
    "print(df.head(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88e377d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9568 entries, 0 to 9567\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      9568 non-null   float64\n",
      " 1   V       9568 non-null   float64\n",
      " 2   AP      9568 non-null   float64\n",
      " 3   RH      9568 non-null   float64\n",
      " 4   PE      9568 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 373.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Checking data types and completeness of data\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a902b09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                AT            V           AP           RH           PE\n",
      "count  9568.000000  9568.000000  9568.000000  9568.000000  9568.000000\n",
      "mean     19.651231    54.305804  1013.259078    73.308978   454.365009\n",
      "std       7.452473    12.707893     5.938784    14.600269    17.066995\n",
      "min       1.810000    25.360000   992.890000    25.560000   420.260000\n",
      "25%      13.510000    41.740000  1009.100000    63.327500   439.750000\n",
      "50%      20.345000    52.080000  1012.940000    74.975000   451.550000\n",
      "75%      25.720000    66.540000  1017.260000    84.830000   468.430000\n",
      "max      37.110000    81.560000  1033.300000   100.160000   495.760000\n"
     ]
    }
   ],
   "source": [
    "# Checking data deviations and and compliance of data with specified intervals\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463a628",
   "metadata": {},
   "source": [
    "As we can see from the analysis above, the data is high-quality, complete, and formatted, ready to build models using it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc60d37",
   "metadata": {},
   "source": [
    "## 2. Data analysis and approach of modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4972d",
   "metadata": {},
   "source": [
    "To choose a modeling approach, first of all, we will evaluate how the presented data correlate with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4d212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AT         V        AP        RH        PE\n",
      "AT  1.000000  0.844107 -0.507549 -0.542535 -0.948128\n",
      "V   0.844107  1.000000 -0.413502 -0.312187 -0.869780\n",
      "AP -0.507549 -0.413502  1.000000  0.099574  0.518429\n",
      "RH -0.542535 -0.312187  0.099574  1.000000  0.389794\n",
      "PE -0.948128 -0.869780  0.518429  0.389794  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Check data distribution in the dataset:\n",
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076bb379",
   "metadata": {},
   "source": [
    "From the obtained correlation data, we can conclude:\n",
    "\n",
    "- AT and V significantly correct with each other;\n",
    "- AT and V have a significant effect on PE;\n",
    "- AP and RH are less influential variables.\n",
    "\n",
    "Our task is to build a model that will predict the values of PE(Net hourly electrical energy output ) based on the values of known variables (Temperature (T), Ambient Pressure (AP), Relative Humidity (RH), Exhaust Vacuum (V)). \n",
    "\n",
    "Considering that we have an adequate dataset that we can use to train the model, we know all the variables that affect the target, then the best choice would be to use **linear regression** to model our predictions.\n",
    "\n",
    "To assess the effectiveness of the method used and the correctness of the selected features, we will prepare three datasets based on the received basic data. Namely:\n",
    "\n",
    "**Dataset 1**, where the features will be AT, AR and RH. We exclude the value of V, since it significantly correlates with AT, and strongly affects the value of the target unit.\n",
    "\n",
    "**Dataset 2**, where the features will be V, AR, and RH. We exclude the AT value since it significantly correlates with V and also strongly affects the value of the target unit.\n",
    "\n",
    "**Dataset 3**, where we use all available features (AT, V, AP, RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41825b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting  dataset to 3 diffrent datasets for modeling\n",
    "\n",
    "df1 = df[['AT','RH']]\n",
    "df2 = df[['V','RH']]\n",
    "df3 = df[['AT','V','RH']]\n",
    "dfy = df['PE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f155bbb",
   "metadata": {},
   "source": [
    "We can now start modeling with linear regression and evaluate the quality and performance of our models with different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94868856",
   "metadata": {},
   "source": [
    "## 3. Model building and calc of metrics for evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d9cbbf",
   "metadata": {},
   "source": [
    "We will use the scikit-learn machine learning library to build a linear regression model and evaluate the models. First, let's download all the necessary tools. \n",
    "\n",
    "To evaluate the models and dataset, we will use metrics such as:\n",
    "\n",
    "- Coefficient of determination (R2)\n",
    "- Mean Squared Error (MSE)\n",
    "- Mean Absolute Error (MBE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad6389ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs for modeling and evaluation \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdcbd3c",
   "metadata": {},
   "source": [
    "An important point is that we could immediately evaluate the obtained metrics of learning results, for each dataset will be divided, in a derived form, into training and test sets, in the proportion of 80% and 20%.\n",
    "\n",
    "Let's start modeling and initial evaluation of the models for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842af3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression score (traning set) 0.9197623321851416\n",
      "Regression score (test set) 0.9256241616264436\n"
     ]
    }
   ],
   "source": [
    "# Building model for dataset 1\n",
    "\n",
    "X= df1\n",
    "y = dfy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
    "\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test) \n",
    "\n",
    "# Modeling results for dataset 1\n",
    "d1_train = linreg.score(X_train, y_train)\n",
    "d1_test = linreg.score(X_test, y_test)\n",
    "\n",
    "# Model evaluating for model  with AT, AR and RH as features. \n",
    "\n",
    "mse_d1 = mean_squared_error(y_test, y_pred)\n",
    "mae_d1 = mean_absolute_error(y_test, y_pred)\n",
    "rmse_d1 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_d1 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Store all results of modeling and evaluating for dataset 1 \n",
    "d1_results = {'train':d1_train, \n",
    "              'test' : d1_test,\n",
    "              'mse' : mse_d1,\n",
    "              'mae': mae_d1, \n",
    "              'rmse' : rmse_d1,\n",
    "              'r2' : r2_d1}\n",
    "\n",
    "print('Regression score (traning set)', d1_train)\n",
    "print('Regression score (test set)', d1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a4043",
   "metadata": {},
   "source": [
    "The first dataset gave excellent regression scores for both training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72eded83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression score (traning set) 0.772340685952033\n",
      "Regression score (test set) 0.7705492485043965\n"
     ]
    }
   ],
   "source": [
    "# Building model for dataset 2\n",
    "\n",
    "X= df2\n",
    "y = dfy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
    "\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test) \n",
    "\n",
    "# Modeling results for dataset 2\n",
    "d2_train = linreg.score(X_train, y_train)\n",
    "d2_test = linreg.score(X_test, y_test)\n",
    "\n",
    "# Model evaluating for model  with V, AR and RH as features.\n",
    "mse_d2 = mean_squared_error(y_test, y_pred)\n",
    "mae_d2  = mean_absolute_error(y_test, y_pred)\n",
    "rmse_d2 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_d2  = r2_score(y_test, y_pred)\n",
    "\n",
    "# Store all results of modeling and evaluating dataset 2\n",
    "d2_results = {'train':d2_train, \n",
    "              'test' : d2_test, \n",
    "              'mse' : mse_d2,\n",
    "              'mae': mae_d2,\n",
    "              'rmse' : rmse_d2, \n",
    "              'r2' : r2_d2}\n",
    "\n",
    "print('Regression score (traning set)', d2_train)\n",
    "print('Regression score (test set)', d2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314991b6",
   "metadata": {},
   "source": [
    "The regression on the second dataset is less successful and the regression scores are extremely low. It is unlikely that we will be able to use this model for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b557182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression score (traning set) 0.9273846176347994\n",
      "Regression score (test set) 0.9322888939219065\n"
     ]
    }
   ],
   "source": [
    "# Building model for dataset 3\n",
    "\n",
    "X= df3\n",
    "y = dfy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
    "\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test) \n",
    "\n",
    "# Modeling results for dataset 3\n",
    "d3_train = linreg.score(X_train, y_train)\n",
    "d3_test = linreg.score(X_test, y_test)\n",
    "\n",
    "# Model evaluating for model  with AT, V, AR and RH as features.\n",
    "\n",
    "mse_d3 = mean_squared_error(y_test, y_pred)\n",
    "mae_d3 = mean_absolute_error(y_test, y_pred)\n",
    "rmse_d3 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2_d3  = r2_score(y_test, y_pred)\n",
    "\n",
    "#Store all results of modeling and evaluating dataset 3.\n",
    "d3_results = {'train':d3_train, \n",
    "              'test' : d3_test, \n",
    "              'mse' : mse_d3,\n",
    "              'mae': mae_d3,\n",
    "              'rmse' : rmse_d3,\n",
    "              'r2' : r2_d3}\n",
    "\n",
    "print('Regression score (traning set)', d3_train)\n",
    "print('Regression score (test set)', d3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71dd7ed",
   "metadata": {},
   "source": [
    "Modeling with all four features shows the best results on both training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853241e3",
   "metadata": {},
   "source": [
    "## 4. Model evaluation and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5b820",
   "metadata": {},
   "source": [
    "Let's prepare a summary table of model performance metrics for each dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6b59037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       train      test        mse       mae      rmse        r2\n",
      "d1  0.919762  0.925624  21.754028  3.726337  4.664121  0.925624\n",
      "d2  0.772341  0.770549  67.111554  6.432966  8.192164  0.770549\n",
      "d3  0.927385  0.932289  19.804675  3.570403  4.450244  0.932289\n"
     ]
    }
   ],
   "source": [
    "# Summary table of each metrics of datasets\n",
    " \n",
    "df_results = pd.DataFrame(data=[d1_results, d2_results, d3_results], index=['d1', 'd2', 'd3'])\n",
    "\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4632c52c",
   "metadata": {},
   "source": [
    "Let's evaluate the results for each metric\n",
    "\n",
    "- Coefficient of determination (R2).\n",
    "\n",
    "The coefficient of determination measures the proportion of the variance explained by the model in the total variance of the target variable. In fact, this measure of quality is the normalized root mean square error. If it is close to one, then the model explains the data well, if it is close to zero, then the predictions are comparable in quality to the constant prediction.\n",
    "\n",
    "In our case, these metrics indicate model on features **d3** as the most optimal. In the case of d2, the indicator is significantly worse.\n",
    "\n",
    "- Mean Squared Error (MSE) and Root Mean Squared Error (RMSE).\n",
    "\n",
    "MSE is used in situations where we need to highlight large errors and choose a model that gives fewer large forecast errors. Blunder becomes more noticeable by squaring the forecast error. And the model that gives us a lower mean square error can be said to have fewer blunders.\n",
    "\n",
    "The model on dataset **d3** shows the smallest value of both metrics and this is preferable for us. But d2 is significantly higher.\n",
    "\n",
    "- Mean Absolute Error (MAE).\n",
    "\n",
    "The Mean Absolute Error (MAE) functional penalizes more for large deviations compared to the absolute mean, and therefore is more sensitive to outliers. When using any of these two functionals, it can be useful to analyze which objects make the greatest contribution to the total error - it is possible that an error was made on these objects when calculating features or a target value.\n",
    "\n",
    "According to this metric, **d3** is also preferable for us, since it has the minimum of the presented values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1947afa",
   "metadata": {},
   "source": [
    "# **Сonclusion:**\n",
    "\n",
    "*Using linear regression, we can successfully predict changes in the PE (Net hourly electrical energy output) indicator using the full amount of data (Temperature (T), Ambient Pressure (AP), Relative Humidity (RH), Exhaust Vacuum (V)). \n",
    "\n",
    "*In case of some data weakness, we could predict PE without feature V (Exhaust Vacuum), with a slight deterioration in the prediction quality.\n",
    "\n",
    "*For such a task, linear regression will be the optimal method, since it will work quickly and efficiently.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
